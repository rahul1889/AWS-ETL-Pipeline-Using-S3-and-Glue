# AWS-ETL-Pipeline-Using-S3-and-Glue
constructing an ETL (Extract, Transform, Load) pipeline in AWS. We'll work with a dataset from the Ocean Restaurant, dealing with CSV data and harnessing essential AWS services such as S3 bucket, AWS Crawler, AWS Data Catalog, Glue Job, and, naturally, another S3 bucket to store the transformed data in Parquet format.
